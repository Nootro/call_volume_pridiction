#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
==============================================================================
Prophet Ultimate Predictor for Call Center - Maximum Accuracy Edition v3.0
==============================================================================

è¶…é«˜ç²¾åº¦ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼æ—¥æ¬¡å‘¼é‡äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  (ç²¾åº¦æœ€å„ªå…ˆç‰ˆ)

ä¸»è¦æ©Ÿèƒ½:
---------
1. é«˜åº¦ãªè‡ªå‹•è¨ºæ–­ã‚·ã‚¹ãƒ†ãƒ  (CV, ANOVA, ACF, ADF, ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æ, STLåˆ†è§£)
2. Optunaã«ã‚ˆã‚‹ãƒ™ã‚¤ã‚ºæœ€é©åŒ– (200+ trials)
3. é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° (30+ features)
   - æ›œæ—¥/æœˆ/å››åŠæœŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° (One-hot + Cyclical)
   - ãƒ©ã‚°ç‰¹å¾´é‡ (1,7,14,28æ—¥)
   - ç§»å‹•å¹³å‡ãƒ»ç§»å‹•æ¨™æº–åå·® (7,14,28æ—¥çª“)
   - æŒ‡æ•°ç§»å‹•å¹³å‡ (EMA)
   - æ›œæ—¥åˆ¥çµ±è¨ˆé‡ (mean, std, quantiles)
   - ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†
   - ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç‰¹å¾´é‡ (æœˆåˆ/æœˆæœ«/å¹´æœ«å¹´å§‹/GW/ãŠç›†)
4. è¤‡æ•°ã®å‰å‡¦ç†æˆ¦ç•¥
   - Box-Coxå¤‰æ›
   - å¯¾æ•°å¤‰æ›
   - æ¨™æº–åŒ–/æ­£è¦åŒ–
   - å¤–ã‚Œå€¤å‡¦ç† (è¤‡æ•°æ‰‹æ³•)
5. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ (5+ãƒ¢ãƒ‡ãƒ«)
   - Optunaæœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«
   - ä¿å®ˆçš„/ä¸­é–“/ã‚¢ã‚°ãƒ¬ãƒƒã‚·ãƒ–ãƒ¢ãƒ‡ãƒ«
   - å­£ç¯€æ€§ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«
6. è©³ç´°æ¤œè¨¼
   - å­¦ç¿’æœŸé–“ã®æœ€å¾Œã®2ãƒ¶æœˆã‚’æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨
   - 1ãƒ¶æœˆç›®/2ãƒ¶æœˆç›®/2ãƒ¶æœˆé–“ã® RMSE/MAE/MAPE
7. 2ãƒ¶æœˆäºˆæ¸¬ (å­¦ç¿’+æ¤œè¨¼ã®å¾Œã®2ãƒ¶æœˆ)
8. åŒ…æ‹¬çš„å¯è¦–åŒ–
9. ãƒ¢ãƒ‡ãƒ«æ°¸ç¶šåŒ–

ä½¿ç”¨ä¾‹:
-------
python prophet_ultimate_predictor_v3.py data.csv

ä½œæˆè€…: AI Assistant
ãƒãƒ¼ã‚¸ãƒ§ãƒ³: 3.0 (Maximum Accuracy Edition)
æœ€çµ‚æ›´æ–°: 2026-02-16
"""

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import calendar
import json
import pickle
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
import sys

# Prophet
try:
    from prophet import Prophet
except ImportError:
    print("âŒ Prophet not installed. Run: pip install prophet")
    sys.exit(1)

# Optuna
try:
    import optuna
    optuna.logging.set_verbosity(optuna.logging.WARNING)
except ImportError:
    print("âŒ Optuna not installed. Run: pip install optuna")
    sys.exit(1)

# çµ±è¨ˆãƒ»æ™‚ç³»åˆ—åˆ†æ
from scipy import stats, signal
from scipy.stats import normaltest, shapiro, jarque_bera, boxcox
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
from statsmodels.tsa.stattools import adfuller, acf, pacf
from statsmodels.tsa.seasonal import STL
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# æ—¥æœ¬ã®ç¥æ—¥
try:
    import jpholiday
except ImportError:
    print("âš ï¸  jpholiday not installed. Run: pip install jpholiday")
    jpholiday = None

# ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
try:
    from tqdm import tqdm
except ImportError:
    tqdm = lambda x, **kwargs: x


# ============================================================================
# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
# ============================================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    handlers=[
        logging.FileHandler('prophet_ultimate_v3.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# ============================================================================
# ProphetUltimatePredictor v3.0 (Maximum Accuracy Edition)
# ============================================================================
class ProphetUltimatePredictor:
    """
    ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼æ—¥æ¬¡å‘¼é‡äºˆæ¸¬ç”¨ã®è¶…é«˜ç²¾åº¦Prophetã‚·ã‚¹ãƒ†ãƒ  (ç²¾åº¦æœ€å„ªå…ˆç‰ˆ)
    
    Parameters
    ----------
    output_dir : str
        å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'prophet_v3_results')
    """
    
    def __init__(self, output_dir: str = 'prophet_v3_results'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)
        
        self.df = None
        self.df_train = None
        self.df_validation = None
        self.df_features = None  # ç‰¹å¾´é‡ä»˜ããƒ‡ãƒ¼ã‚¿
        self.diagnostics = {}
        self.models = {}
        self.forecasts = {}
        self.best_params = {}
        self.ensemble_forecast = None
        self.validation_metrics = {}
        self.feature_importance = {}
        
        logger.info(f"âœ… ProphetUltimatePredictor v3.0 (Maximum Accuracy) initialized")
        logger.info(f"ğŸ“ Output: {self.output_dir}")
    
    # ========================================================================
    # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & åˆ†å‰²
    # ========================================================================
    def load_data(self, filepath: Union[str, Path], date_col: str = 'ds', 
                  value_col: str = 'y', validation_months: int = 2) -> pd.DataFrame:
        """
        ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨åŸºæœ¬å‰å‡¦ç† (å­¦ç¿’æœŸé–“ã®æœ€å¾Œã®2ãƒ¶æœˆã‚’æ¤œè¨¼ç”¨ã«åˆ†å‰²)
        
        Parameters
        ----------
        filepath : str or Path
            CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        date_col : str
            æ—¥ä»˜ã‚«ãƒ©ãƒ å
        value_col : str
            ç›®çš„å¤‰æ•°ã‚«ãƒ©ãƒ å
        validation_months : int
            æ¤œè¨¼æœŸé–“ (æœˆæ•°ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2)
        
        Returns
        -------
        pd.DataFrame
            å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        """
        logger.info(f"ğŸ“‚ Loading data from {filepath}")
        
        df = pd.read_csv(filepath)
        
        # ã‚«ãƒ©ãƒ åæ¨™æº–åŒ–
        if date_col not in df.columns or value_col not in df.columns:
            logger.warning(f"âš ï¸  Columns not found. Available: {df.columns.tolist()}")
            date_candidates = [c for c in df.columns if 'date' in c.lower() or 'ds' in c.lower()]
            value_candidates = [c for c in df.columns if c.lower() in ['y', 'value', 'volume', 'calls']]
            
            if date_candidates:
                date_col = date_candidates[0]
            if value_candidates:
                value_col = value_candidates[0]
        
        df = df[[date_col, value_col]].copy()
        df.columns = ['ds', 'y']
        
        # æ—¥ä»˜å¤‰æ›
        df['ds'] = pd.to_datetime(df['ds'])
        df = df.sort_values('ds').reset_index(drop=True)
        
        # æ¬ æå€¤å‡¦ç†
        missing_count = df['y'].isna().sum()
        if missing_count > 0:
            logger.warning(f"âš ï¸  {missing_count} missing values detected. Filling with interpolation.")
            df['y'] = df['y'].interpolate(method='time')
            df['y'] = df['y'].fillna(df['y'].median())
        
        # è² å€¤å‡¦ç†
        negative_count = (df['y'] < 0).sum()
        if negative_count > 0:
            logger.warning(f"âš ï¸  {negative_count} negative values detected. Clipping to 0.")
            df['y'] = df['y'].clip(lower=0)
        
        # æ¤œè¨¼æœŸé–“ã®è¨ˆç®— (å­¦ç¿’æœŸé–“ã®æœ€å¾Œã®2ãƒ¶æœˆ)
        max_date = df['ds'].max()
        validation_start = max_date - relativedelta(months=validation_months) + timedelta(days=1)
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        self.df = df
        self.df_train = df[df['ds'] < validation_start].copy()
        self.df_validation = df[df['ds'] >= validation_start].copy()
        
        logger.info(f"âœ… Data loaded: {len(df)} rows, {df['ds'].min().date()} to {df['ds'].max().date()}")
        logger.info(f"  ğŸ“Š Train: {len(self.df_train)} rows ({self.df_train['ds'].min().date()} to {self.df_train['ds'].max().date()})")
        logger.info(f"  ğŸ” Validation: {len(self.df_validation)} rows ({self.df_validation['ds'].min().date()} to {self.df_validation['ds'].max().date()})")
        
        return df
    
    # ========================================================================
    # 2. åŒ…æ‹¬çš„è¨ºæ–­ã‚·ã‚¹ãƒ†ãƒ 
    # ========================================================================
    def run_comprehensive_diagnostics(self) -> Dict:
        """
        åŒ…æ‹¬çš„æ™‚ç³»åˆ—è¨ºæ–­ã‚’å®Ÿè¡Œ (å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã¿)
        """
        logger.info("ğŸ” Running comprehensive diagnostics on training data...")
        
        df = self.df_train.copy()
        y = df['y'].values
        
        diagnostics = {}
        
        # åŸºæœ¬çµ±è¨ˆé‡
        diagnostics['basic_stats'] = {
            'mean': float(np.mean(y)),
            'std': float(np.std(y)),
            'cv': float(np.std(y) / np.mean(y)),
            'min': float(np.min(y)),
            'max': float(np.max(y)),
            'q25': float(np.percentile(y, 25)),
            'median': float(np.median(y)),
            'q75': float(np.percentile(y, 75)),
            'iqr': float(np.percentile(y, 75) - np.percentile(y, 25)),
            'skewness': float(stats.skew(y)),
            'kurtosis': float(stats.kurtosis(y))
        }
        
        cv = diagnostics['basic_stats']['cv']
        logger.info(f"  ğŸ“Š Mean: {diagnostics['basic_stats']['mean']:.1f}, CV: {cv:.3f}")
        
        # æ­£è¦æ€§æ¤œå®š
        try:
            _, p_shapiro = shapiro(y[:5000] if len(y) > 5000 else y)
            _, p_normal = normaltest(y)
            
            diagnostics['normality'] = {
                'shapiro_p': float(p_shapiro),
                'normaltest_p': float(p_normal),
                'is_normal': bool(p_normal > 0.05)
            }
            logger.info(f"  ğŸ“ˆ Normality test p-value: {p_normal:.4f}")
        except Exception as e:
            logger.warning(f"  âš ï¸  Normality test failed: {e}")
            diagnostics['normality'] = {'is_normal': False}
        
        # å®šå¸¸æ€§æ¤œå®š (ADF)
        try:
            adf_result = adfuller(y, autolag='AIC')
            diagnostics['stationarity'] = {
                'adf_statistic': float(adf_result[0]),
                'adf_p_value': float(adf_result[1]),
                'is_stationary': bool(adf_result[1] < 0.05)
            }
            logger.info(f"  ğŸ“‰ ADF p-value: {adf_result[1]:.4f}")
        except Exception as e:
            logger.warning(f"  âš ï¸  ADF test failed: {e}")
            diagnostics['stationarity'] = {'is_stationary': False}
        
        # è‡ªå·±ç›¸é–¢
        try:
            acf_values = acf(y, nlags=min(30, len(y)//2 - 1), fft=True)
            pacf_values = pacf(y, nlags=min(30, len(y)//2 - 1))
            
            diagnostics['autocorrelation'] = {
                'acf_lag1': float(acf_values[1]),
                'acf_lag7': float(acf_values[7]) if len(acf_values) > 7 else 0.0,
                'pacf_lag1': float(pacf_values[1])
            }
            logger.info(f"  ğŸ”„ ACF(lag=7): {diagnostics['autocorrelation']['acf_lag7']:.3f}")
        except Exception as e:
            logger.warning(f"  âš ï¸  ACF/PACF failed: {e}")
            diagnostics['autocorrelation'] = {}
        
        # æ›œæ—¥åŠ¹æœ (ANOVA)
        df['weekday'] = df['ds'].dt.dayofweek
        try:
            weekday_groups = [df[df['weekday'] == i]['y'].values for i in range(7)]
            f_stat, p_value = stats.f_oneway(*weekday_groups)
            
            diagnostics['weekday_effect'] = {
                'f_statistic': float(f_stat),
                'p_value': float(p_value),
                'has_effect': bool(p_value < 0.05)
            }
            logger.info(f"  ğŸ“… Weekday ANOVA p-value: {p_value:.4e}")
        except Exception as e:
            logger.warning(f"  âš ï¸  Weekday ANOVA failed: {e}")
            diagnostics['weekday_effect'] = {'has_effect': False}
        
        # å¤–ã‚Œå€¤æ¤œå‡º
        q1, q3 = np.percentile(y, [25, 75])
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        outliers = (y < lower_bound) | (y > upper_bound)
        
        diagnostics['outliers'] = {
            'count': int(np.sum(outliers)),
            'percentage': float(100 * np.sum(outliers) / len(y)),
            'lower_bound': float(lower_bound),
            'upper_bound': float(upper_bound)
        }
        logger.info(f"  ğŸš¨ Outliers: {diagnostics['outliers']['count']} ({diagnostics['outliers']['percentage']:.2f}%)")
        
        self.diagnostics = diagnostics
        
        with open(self.output_dir / 'diagnostics.json', 'w', encoding='utf-8') as f:
            json.dump(diagnostics, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… Diagnostics completed")
        
        return diagnostics
    
    # ========================================================================
    # 3. é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° (30+ features)
    # ========================================================================
    def create_advanced_features(self, df: pd.DataFrame, is_train: bool = True) -> pd.DataFrame:
        """
        é«˜åº¦ãªç‰¹å¾´é‡ã‚’ç”Ÿæˆ (30+ features for maximum accuracy)
        
        Parameters
        ----------
        df : pd.DataFrame
            å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ (ds, y)
        is_train : bool
            å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã©ã†ã‹ (çµ±è¨ˆé‡è¨ˆç®—ç”¨)
        
        Returns
        -------
        pd.DataFrame
            ç‰¹å¾´é‡ä»˜ããƒ‡ãƒ¼ã‚¿
        """
        logger.info(f"ğŸ”§ Creating advanced features (train={is_train})...")
        
        df = df.copy()
        
        # ------------------------------------------------------------------
        # 3.1 æ™‚é–“ç‰¹å¾´é‡
        # ------------------------------------------------------------------
        df['year'] = df['ds'].dt.year
        df['month'] = df['ds'].dt.month
        df['day'] = df['ds'].dt.day
        df['weekday'] = df['ds'].dt.dayofweek
        df['quarter'] = df['ds'].dt.quarter
        df['week_of_year'] = df['ds'].dt.isocalendar().week
        df['day_of_year'] = df['ds'].dt.dayofyear
        
        # ------------------------------------------------------------------
        # 3.2 å‘¨æœŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° (Cyclical encoding)
        # ------------------------------------------------------------------
        df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)
        df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 7)
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)
        df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)
        df['quarter_sin'] = np.sin(2 * np.pi * df['quarter'] / 4)
        df['quarter_cos'] = np.cos(2 * np.pi * df['quarter'] / 4)
        
        # ------------------------------------------------------------------
        # 3.3 One-hot encoding (æ›œæ—¥)
        # ------------------------------------------------------------------
        for i in range(7):
            df[f'is_weekday_{i}'] = (df['weekday'] == i).astype(int)
        
        # ------------------------------------------------------------------
        # 3.4 ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç‰¹å¾´é‡
        # ------------------------------------------------------------------
        df['is_month_start'] = (df['day'] <= 3).astype(int)
        df['is_month_end'] = (df['day'] >= 28).astype(int)
        df['is_weekend'] = (df['weekday'] >= 5).astype(int)
        df['is_monday'] = (df['weekday'] == 0).astype(int)
        df['is_friday'] = (df['weekday'] == 4).astype(int)
        
        # ç¥æ—¥ãƒ•ãƒ©ã‚°
        if jpholiday is not None:
            df['is_holiday'] = df['ds'].apply(lambda x: int(jpholiday.is_holiday(x)))
        else:
            df['is_holiday'] = 0
        
        # å¹´æœ«å¹´å§‹ãƒ»GWãƒ»ãŠç›†
        df['is_year_end'] = ((df['month'] == 12) & (df['day'] >= 28)).astype(int)
        df['is_new_year'] = ((df['month'] == 1) & (df['day'] <= 7)).astype(int)
        df['is_golden_week'] = ((df['month'] == 5) & (df['day'] >= 1) & (df['day'] <= 7)).astype(int)
        df['is_obon'] = ((df['month'] == 8) & (df['day'] >= 13) & (df['day'] <= 16)).astype(int)
        
        # ------------------------------------------------------------------
        # 3.5 ãƒ©ã‚°ç‰¹å¾´é‡ (lag features)
        # ------------------------------------------------------------------
        if is_train and 'y' in df.columns:
            for lag in [1, 7, 14, 28]:
                df[f'lag_{lag}'] = df['y'].shift(lag)
        
        # ------------------------------------------------------------------
        # 3.6 ç§»å‹•çµ±è¨ˆé‡ (rolling statistics)
        # ------------------------------------------------------------------
        if is_train and 'y' in df.columns:
            for window in [7, 14, 28]:
                df[f'rolling_mean_{window}'] = df['y'].rolling(window=window, min_periods=1).mean()
                df[f'rolling_std_{window}'] = df['y'].rolling(window=window, min_periods=1).std()
                df[f'rolling_min_{window}'] = df['y'].rolling(window=window, min_periods=1).min()
                df[f'rolling_max_{window}'] = df['y'].rolling(window=window, min_periods=1).max()
        
        # ------------------------------------------------------------------
        # 3.7 æŒ‡æ•°ç§»å‹•å¹³å‡ (EMA)
        # ------------------------------------------------------------------
        if is_train and 'y' in df.columns:
            df['ema_7'] = df['y'].ewm(span=7, adjust=False).mean()
            df['ema_14'] = df['y'].ewm(span=14, adjust=False).mean()
        
        # ------------------------------------------------------------------
        # 3.8 æ›œæ—¥åˆ¥çµ±è¨ˆé‡ (weekday statistics)
        # ------------------------------------------------------------------
        if is_train and 'y' in df.columns:
            weekday_stats = df.groupby('weekday')['y'].agg(['mean', 'std']).reset_index()
            weekday_stats.columns = ['weekday', 'weekday_mean', 'weekday_std']
            df = df.merge(weekday_stats, on='weekday', how='left')
            
            # æ›œæ—¥åˆ¥åˆ†ä½ç‚¹
            weekday_quantiles = df.groupby('weekday')['y'].quantile([0.25, 0.75]).unstack()
            weekday_quantiles.columns = ['weekday_q25', 'weekday_q75']
            weekday_quantiles = weekday_quantiles.reset_index()
            df = df.merge(weekday_quantiles, on='weekday', how='left')
        
        # ------------------------------------------------------------------
        # 3.9 ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ† (å˜ç´”ç·šå½¢ãƒˆãƒ¬ãƒ³ãƒ‰)
        # ------------------------------------------------------------------
        df['trend'] = np.arange(len(df))
        
        # NaNåŸ‹ã‚ (ãƒ©ã‚°ç‰¹å¾´é‡ç­‰)
        df = df.fillna(method='bfill').fillna(method='ffill').fillna(0)
        
        logger.info(f"  âœ… Created {len(df.columns) - 2} features (excluding ds, y)")
        
        return df
    
    # ========================================================================
    # 4. ç¥æ—¥ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆ
    # ========================================================================
    def create_holiday_dataframe(self, start_year: int = None, 
                                  end_year: int = None) -> pd.DataFrame:
        """
        æ—¥æœ¬ã®ç¥æ—¥ãƒ»ç‰¹æ®Šæ—¥ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆ
        """
        if self.df is None:
            raise ValueError("Data not loaded. Call load_data() first.")
        
        if start_year is None:
            start_year = self.df['ds'].dt.year.min()
        if end_year is None:
            end_year = self.df['ds'].dt.year.max() + 2
        
        logger.info(f"ğŸ“… Creating holiday dataframe ({start_year}-{end_year})")
        
        holidays = []
        
        # æ—¥æœ¬ã®ç¥æ—¥
        if jpholiday is not None:
            for year in range(start_year, end_year + 1):
                for month in range(1, 13):
                    for day in range(1, 32):
                        try:
                            date = datetime(year, month, day)
                            if jpholiday.is_holiday(date):
                                holidays.append({
                                    'ds': date,
                                    'holiday': 'jp_holiday',
                                    'lower_window': 0,
                                    'upper_window': 0,
                                    'prior_scale': 20.0
                                })
                        except ValueError:
                            continue
            logger.info(f"  ğŸŒ Added {len(holidays)} Japanese holidays")
        
        # æœˆåˆ (1-3æ—¥)
        for year in range(start_year, end_year + 1):
            for month in range(1, 13):
                for day in [1, 2, 3]:
                    try:
                        holidays.append({
                            'ds': datetime(year, month, day),
                            'holiday': 'month_start',
                            'lower_window': 0,
                            'upper_window': 0,
                            'prior_scale': 15.0
                        })
                    except ValueError:
                        continue
        
        # æœˆæœ« (æœ€çµ‚3æ—¥)
        for year in range(start_year, end_year + 1):
            for month in range(1, 13):
                last_day = calendar.monthrange(year, month)[1]
                for day in [last_day - 2, last_day - 1, last_day]:
                    if day > 0:
                        try:
                            holidays.append({
                                'ds': datetime(year, month, day),
                                'holiday': 'month_end',
                                'lower_window': 0,
                                'upper_window': 0,
                                'prior_scale': 15.0
                            })
                        except ValueError:
                            continue
        
        # å¹´æœ«å¹´å§‹
        for year in range(start_year, end_year + 1):
            for day in range(28, 32):
                try:
                    holidays.append({
                        'ds': datetime(year, 12, day),
                        'holiday': 'year_end',
                        'lower_window': 0,
                        'upper_window': 0,
                        'prior_scale': 30.0
                    })
                except ValueError:
                    continue
            
            for day in range(1, 8):
                try:
                    holidays.append({
                        'ds': datetime(year, 1, day),
                        'holiday': 'new_year',
                        'lower_window': 0,
                        'upper_window': 0,
                        'prior_scale': 30.0
                    })
                except ValueError:
                    continue
        
        holidays_df = pd.DataFrame(holidays)
        holidays_df = holidays_df.sort_values('prior_scale', ascending=False).drop_duplicates('ds', keep='first')
        holidays_df = holidays_df.sort_values('ds').reset_index(drop=True)
        
        logger.info(f"âœ… Holiday dataframe created: {len(holidays_df)} entries")
        
        return holidays_df
    
    # ========================================================================
    # 5. Optunaã«ã‚ˆã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
    # ========================================================================
    def optimize_with_optuna(self, df: pd.DataFrame, holidays: pd.DataFrame = None,
                             n_trials: int = 200, cv_horizon_days: int = 30) -> Dict:
        """
        Optunaã«ã‚ˆã‚‹ãƒ™ã‚¤ã‚ºæœ€é©åŒ–
        
        Parameters
        ----------
        df : pd.DataFrame
            å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
        holidays : pd.DataFrame
            ç¥æ—¥ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        n_trials : int
            è©¦è¡Œå›æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 200)
        cv_horizon_days : int
            äº¤å·®æ¤œè¨¼ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ (æ—¥æ•°)
        
        Returns
        -------
        dict
            æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        logger.info(f"ğŸ” Optimizing hyperparameters with Optuna ({n_trials} trials)...")
        
        def objective(trial):
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            params = {
                'changepoint_prior_scale': trial.suggest_float('changepoint_prior_scale', 0.001, 0.5, log=True),
                'seasonality_prior_scale': trial.suggest_float('seasonality_prior_scale', 0.01, 20.0, log=True),
                'holidays_prior_scale': trial.suggest_float('holidays_prior_scale', 0.01, 50.0, log=True),
                'seasonality_mode': trial.suggest_categorical('seasonality_mode', ['additive', 'multiplicative']),
                'changepoint_range': trial.suggest_float('changepoint_range', 0.8, 0.95),
                'n_changepoints': trial.suggest_int('n_changepoints', 15, 35),
                'weekly_fourier': trial.suggest_int('weekly_fourier', 3, 15),
                'monthly_fourier': trial.suggest_int('monthly_fourier', 5, 20),
                'yearly_fourier': trial.suggest_int('yearly_fourier', 10, 25)
            }
            
            try:
                # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
                model = Prophet(
                    changepoint_prior_scale=params['changepoint_prior_scale'],
                    seasonality_prior_scale=params['seasonality_prior_scale'],
                    holidays_prior_scale=params['holidays_prior_scale'],
                    seasonality_mode=params['seasonality_mode'],
                    changepoint_range=params['changepoint_range'],
                    n_changepoints=params['n_changepoints'],
                    holidays=holidays,
                    daily_seasonality=False,
                    weekly_seasonality=False,
                    yearly_seasonality=False,
                    interval_width=0.95
                )
                
                # ã‚«ã‚¹ã‚¿ãƒ å­£ç¯€æ€§
                model.add_seasonality(name='weekly', period=7, fourier_order=params['weekly_fourier'])
                model.add_seasonality(name='monthly', period=30.5, fourier_order=params['monthly_fourier'])
                model.add_seasonality(name='yearly', period=365.25, fourier_order=params['yearly_fourier'])
                
                # å­¦ç¿’ (æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã¯é™¤ã)
                model.fit(df[['ds', 'y']])
                
                # ç°¡æ˜“äº¤å·®æ¤œè¨¼ (æœ€å¾Œã® cv_horizon_days ã‚’ä½¿ç”¨)
                if len(df) > cv_horizon_days:
                    train_cv = df.iloc[:-cv_horizon_days]
                    test_cv = df.iloc[-cv_horizon_days:]
                    
                    model_cv = Prophet(
                        changepoint_prior_scale=params['changepoint_prior_scale'],
                        seasonality_prior_scale=params['seasonality_prior_scale'],
                        holidays_prior_scale=params['holidays_prior_scale'],
                        seasonality_mode=params['seasonality_mode'],
                        changepoint_range=params['changepoint_range'],
                        n_changepoints=params['n_changepoints'],
                        holidays=holidays,
                        daily_seasonality=False,
                        weekly_seasonality=False,
                        yearly_seasonality=False
                    )
                    
                    model_cv.add_seasonality(name='weekly', period=7, fourier_order=params['weekly_fourier'])
                    model_cv.add_seasonality(name='monthly', period=30.5, fourier_order=params['monthly_fourier'])
                    model_cv.add_seasonality(name='yearly', period=365.25, fourier_order=params['yearly_fourier'])
                    
                    model_cv.fit(train_cv[['ds', 'y']])
                    future_cv = model_cv.make_future_dataframe(periods=cv_horizon_days)
                    forecast_cv = model_cv.predict(future_cv)
                    
                    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒ¼ã‚¸
                    forecast_cv = forecast_cv[forecast_cv['ds'].isin(test_cv['ds'])]
                    merged = pd.merge(test_cv[['ds', 'y']], forecast_cv[['ds', 'yhat']], on='ds')
                    
                    if len(merged) > 0:
                        mae = mean_absolute_error(merged['y'], merged['yhat'])
                        return mae
                    else:
                        return 1e10
                else:
                    return 1e10
                    
            except Exception as e:
                logger.warning(f"  âš ï¸  Trial failed: {e}")
                return 1e10
        
        # Optunaæœ€é©åŒ–å®Ÿè¡Œ
        study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))
        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)
        
        best_params = study.best_params
        best_mae = study.best_value
        
        logger.info(f"âœ… Optuna optimization completed")
        logger.info(f"  ğŸ“Š Best MAE: {best_mae:.2f}")
        logger.info(f"  âš™ï¸  Best params: {best_params}")
        
        self.best_params = best_params
        
        # çµæœä¿å­˜
        with open(self.output_dir / 'best_params_optuna.json', 'w', encoding='utf-8') as f:
            json.dump({'params': best_params, 'mae': float(best_mae)}, f, indent=2, ensure_ascii=False)
        
        return best_params
    
    # ========================================================================
    # 6. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«è¨“ç·´ (5+ãƒ¢ãƒ‡ãƒ«)
    # ========================================================================
    def fit_ensemble_models(self, df: pd.DataFrame, holidays: pd.DataFrame = None) -> Dict:
        """
        è¤‡æ•°ã®Prophetãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        
        Parameters
        ----------
        df : pd.DataFrame
            å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
        holidays : pd.DataFrame
            ç¥æ—¥ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        
        Returns
        -------
        dict
            ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬çµæœ
        """
        # 2ãƒ¶æœˆå¾Œã®æ—¥æ•°ã‚’è¨ˆç®—
        max_date = df['ds'].max()
        future_end = max_date + relativedelta(months=2)
        horizon_days = (future_end - max_date).days
        
        logger.info(f"ğŸ¯ Training ensemble models (5+ models, 2-month forecast: {horizon_days} days)...")
        logger.info(f"  ğŸ“… Forecast period: {max_date.date()} â†’ {future_end.date()}")
        
        models = {}
        forecasts = {}
        
        # ------------------------------------------------------------------
        # ãƒ¢ãƒ‡ãƒ«1: Optunaæœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«
        # ------------------------------------------------------------------
        logger.info("  ğŸ”§ Model 1: Optuna Optimized")
        try:
            best_params = self.best_params if self.best_params else {
                'changepoint_prior_scale': 0.1,
                'seasonality_prior_scale': 10.0,
                'holidays_prior_scale': 20.0,
                'seasonality_mode': 'multiplicative',
                'changepoint_range': 0.9,
                'n_changepoints': 25,
                'weekly_fourier': 8,
                'monthly_fourier': 12,
                'yearly_fourier': 15
            }
            
            model1 = Prophet(
                changepoint_prior_scale=best_params.get('changepoint_prior_scale', 0.1),
                seasonality_prior_scale=best_params.get('seasonality_prior_scale', 10.0),
                holidays_prior_scale=best_params.get('holidays_prior_scale', 20.0),
                seasonality_mode=best_params.get('seasonality_mode', 'multiplicative'),
                changepoint_range=best_params.get('changepoint_range', 0.9),
                n_changepoints=best_params.get('n_changepoints', 25),
                holidays=holidays,
                daily_seasonality=False,
                weekly_seasonality=False,
                yearly_seasonality=False,
                interval_width=0.95,
                uncertainty_samples=1000
            )
            
            model1.add_seasonality(name='weekly', period=7, fourier_order=best_params.get('weekly_fourier', 8))
            model1.add_seasonality(name='monthly', period=30.5, fourier_order=best_params.get('monthly_fourier', 12))
            model1.add_seasonality(name='yearly', period=365.25, fourier_order=best_params.get('yearly_fourier', 15))
            
            model1.fit(df[['ds', 'y']])
            future1 = model1.make_future_dataframe(periods=horizon_days)
            forecast1 = model1.predict(future1)
            
            models['optuna'] = model1
            forecasts['optuna'] = forecast1
            
            logger.info("    âœ… Model 1 trained")
        except Exception as e:
            logger.error(f"    âŒ Model 1 failed: {e}")
        
        # ------------------------------------------------------------------
        # ãƒ¢ãƒ‡ãƒ«2: ä¿å®ˆçš„ãƒ¢ãƒ‡ãƒ«
        # ------------------------------------------------------------------
        logger.info("  ğŸ”§ Model 2: Conservative")
        try:
            model2 = Prophet(
                changepoint_prior_scale=0.001,
                seasonality_prior_scale=1.0,
                holidays_prior_scale=10.0,
                seasonality_mode='additive',
                changepoint_range=0.85,
                n_changepoints=15,
                holidays=holidays,
                daily_seasonality=False,
                weekly_seasonality=False,
                yearly_seasonality=False,
                interval_width=0.95,
                uncertainty_samples=1000
            )
            
            model2.add_seasonality(name='weekly', period=7, fourier_order=3)
            model2.add_seasonality(name='monthly', period=30.5, fourier_order=5)
            model2.add_seasonality(name='yearly', period=365.25, fourier_order=10)
            
            model2.fit(df[['ds', 'y']])
            future2 = model2.make_future_dataframe(periods=horizon_days)
            forecast2 = model2.predict(future2)
            
            models['conservative'] = model2
            forecasts['conservative'] = forecast2
            
            logger.info("    âœ… Model 2 trained")
        except Exception as e:
            logger.error(f"    âŒ Model 2 failed: {e}")
        
        # ------------------------------------------------------------------
        # ãƒ¢ãƒ‡ãƒ«3: ä¸­é–“ãƒ¢ãƒ‡ãƒ«
        # ------------------------------------------------------------------
        logger.info("  ğŸ”§ Model 3: Moderate")
        try:
            model3 = Prophet(
                changepoint_prior_scale=0.05,
                seasonality_prior_scale=10.0,
                holidays_prior_scale=20.0,
                seasonality_mode='multiplicative',
                changepoint_range=0.9,
                n_changepoints=25,
                holidays=holidays,
                daily_seasonality=False,
                weekly_seasonality=False,
                yearly_seasonality=False,
                interval_width=0.95,
                uncertainty_samples=1000
            )
            
            model3.add_seasonality(name='weekly', period=7, fourier_order=5)
            model3.add_seasonality(name='monthly', period=30.5, fourier_order=10)
            model3.add_seasonality(name='yearly', period=365.25, fourier_order=15)
            
            model3.fit(df[['ds', 'y']])
            future3 = model3.make_future_dataframe(periods=horizon_days)
            forecast3 = model3.predict(future3)
            
            models['moderate'] = model3
            forecasts['moderate'] = forecast3
            
            logger.info("    âœ… Model 3 trained")
        except Exception as e:
            logger.error(f"    âŒ Model 3 failed: {e}")
        
        # ------------------------------------------------------------------
        # ãƒ¢ãƒ‡ãƒ«4: ã‚¢ã‚°ãƒ¬ãƒƒã‚·ãƒ–ãƒ¢ãƒ‡ãƒ«
        # ------------------------------------------------------------------
        logger.info("  ğŸ”§ Model 4: Aggressive")
        try:
            model4 = Prophet(
                changepoint_prior_scale=0.5,
                seasonality_prior_scale=20.0,
                holidays_prior_scale=30.0,
                seasonality_mode='multiplicative',
                changepoint_range=0.95,
                n_changepoints=35,
                holidays=holidays,
                daily_seasonality=False,
                weekly_seasonality=False,
                yearly_seasonality=False,
                interval_width=0.95,
                uncertainty_samples=1000
            )
            
            model4.add_seasonality(name='weekly', period=7, fourier_order=12)
            model4.add_seasonality(name='monthly', period=30.5, fourier_order=18)
            model4.add_seasonality(name='yearly', period=365.25, fourier_order=22)
            
            model4.fit(df[['ds', 'y']])
            future4 = model4.make_future_dataframe(periods=horizon_days)
            forecast4 = model4.predict(future4)
            
            models['aggressive'] = model4
            forecasts['aggressive'] = forecast4
            
            logger.info("    âœ… Model 4 trained")
        except Exception as e:
            logger.error(f"    âŒ Model 4 failed: {e}")
        
        # ------------------------------------------------------------------
        # ãƒ¢ãƒ‡ãƒ«5: å­£ç¯€æ€§ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«
        # ------------------------------------------------------------------
        logger.info("  ğŸ”§ Model 5: Seasonality Focused")
        try:
            model5 = Prophet(
                changepoint_prior_scale=0.01,
                seasonality_prior_scale=30.0,
                holidays_prior_scale=40.0,
                seasonality_mode='multiplicative',
                changepoint_range=0.85,
                n_changepoints=20,
                holidays=holidays,
                daily_seasonality=False,
                weekly_seasonality=False,
                yearly_seasonality=False,
                interval_width=0.95,
                uncertainty_samples=1000
            )
            
            model5.add_seasonality(name='weekly', period=7, fourier_order=15)
            model5.add_seasonality(name='monthly', period=30.5, fourier_order=20)
            model5.add_seasonality(name='quarterly', period=91.25, fourier_order=8)
            model5.add_seasonality(name='yearly', period=365.25, fourier_order=25)
            
            model5.fit(df[['ds', 'y']])
            future5 = model5.make_future_dataframe(periods=horizon_days)
            forecast5 = model5.predict(future5)
            
            models['seasonality'] = model5
            forecasts['seasonality'] = forecast5
            
            logger.info("    âœ… Model 5 trained")
        except Exception as e:
            logger.error(f"    âŒ Model 5 failed: {e}")
        
        # ------------------------------------------------------------------
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« (é‡ã¿ä»˜ãå¹³å‡)
        # ------------------------------------------------------------------
        logger.info("  ğŸ¯ Creating ensemble forecast...")
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½è©•ä¾¡
        train_maes = {}
        for name, forecast in forecasts.items():
            train_forecast = forecast[forecast['ds'].isin(df['ds'])]
            merged = pd.merge(df[['ds', 'y']], train_forecast[['ds', 'yhat']], on='ds')
            if len(merged) > 0:
                mae = mean_absolute_error(merged['y'], merged['yhat'])
                train_maes[name] = mae
                logger.info(f"    ğŸ“Š {name} MAE: {mae:.2f}")
        
        # é€†MAEã§é‡ã¿è¨ˆç®—
        weights = {name: 1.0 / mae for name, mae in train_maes.items()}
        total_weight = sum(weights.values())
        weights = {name: w / total_weight for name, w in weights.items()}
        
        logger.info(f"    âš–ï¸  Ensemble weights: {weights}")
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        ensemble_forecast = forecasts[list(forecasts.keys())[0]].copy()
        ensemble_forecast['yhat'] = sum(forecasts[name]['yhat'] * weights[name] for name in forecasts.keys())
        ensemble_forecast['yhat_lower'] = sum(forecasts[name]['yhat_lower'] * weights[name] for name in forecasts.keys())
        ensemble_forecast['yhat_upper'] = sum(forecasts[name]['yhat_upper'] * weights[name] for name in forecasts.keys())
        
        self.models = models
        self.forecasts = forecasts
        self.ensemble_forecast = ensemble_forecast
        
        logger.info("âœ… Ensemble models trained")
        
        return {
            'models': models,
            'forecasts': forecasts,
            'ensemble': ensemble_forecast,
            'weights': weights
        }
    
    # ========================================================================
    # 7. è©³ç´°æ¤œè¨¼
    # ========================================================================
    def validate_forecast(self) -> Dict:
        """
        æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬æ€§èƒ½ã‚’è©•ä¾¡
        - 1ãƒ¶æœˆç›®ã® RMSE/MAE/MAPE
        - 2ãƒ¶æœˆç›®ã® RMSE/MAE/MAPE
        - 2ãƒ¶æœˆé–“ã® RMSE/MAE/MAPE
        """
        logger.info("ğŸ” Validating forecast on holdout data...")
        
        if self.df_validation is None or len(self.df_validation) == 0:
            logger.warning("âš ï¸  No validation data available")
            return {}
        
        # æ¤œè¨¼æœŸé–“ã®äºˆæ¸¬å€¤ã‚’æŠ½å‡º
        forecast_val = self.ensemble_forecast[
            self.ensemble_forecast['ds'].isin(self.df_validation['ds'])
        ].copy()
        
        merged = pd.merge(
            self.df_validation[['ds', 'y']], 
            forecast_val[['ds', 'yhat']], 
            on='ds'
        )
        
        if len(merged) == 0:
            logger.warning("âš ï¸  No matching dates in validation period")
            return {}
        
        # æœˆåˆ¥ã«åˆ†å‰²
        merged['year_month'] = merged['ds'].dt.to_period('M')
        months = sorted(merged['year_month'].unique())
        
        validation_metrics = {}
        
        # 1ãƒ¶æœˆç›®
        if len(months) >= 1:
            month1_data = merged[merged['year_month'] == months[0]]
            y_true_m1 = month1_data['y'].values
            y_pred_m1 = month1_data['yhat'].values
            
            rmse_m1 = np.sqrt(mean_squared_error(y_true_m1, y_pred_m1))
            mae_m1 = mean_absolute_error(y_true_m1, y_pred_m1)
            mape_m1 = np.mean(np.abs((y_true_m1 - y_pred_m1) / y_true_m1)) * 100
            
            validation_metrics['month_1'] = {
                'period': str(months[0]),
                'days': len(month1_data),
                'rmse': float(rmse_m1),
                'mae': float(mae_m1),
                'mape': float(mape_m1)
            }
            
            logger.info(f"  ğŸ“Š Month 1 ({months[0]}): RMSE={rmse_m1:.2f}, MAE={mae_m1:.2f}, MAPE={mape_m1:.2f}%")
        
        # 2ãƒ¶æœˆç›®
        if len(months) >= 2:
            month2_data = merged[merged['year_month'] == months[1]]
            y_true_m2 = month2_data['y'].values
            y_pred_m2 = month2_data['yhat'].values
            
            rmse_m2 = np.sqrt(mean_squared_error(y_true_m2, y_pred_m2))
            mae_m2 = mean_absolute_error(y_true_m2, y_pred_m2)
            mape_m2 = np.mean(np.abs((y_true_m2 - y_pred_m2) / y_true_m2)) * 100
            
            validation_metrics['month_2'] = {
                'period': str(months[1]),
                'days': len(month2_data),
                'rmse': float(rmse_m2),
                'mae': float(mae_m2),
                'mape': float(mape_m2)
            }
            
            logger.info(f"  ğŸ“Š Month 2 ({months[1]}): RMSE={rmse_m2:.2f}, MAE={mae_m2:.2f}, MAPE={mape_m2:.2f}%")
        
        # 2ãƒ¶æœˆé–“å…¨ä½“
        y_true_all = merged['y'].values
        y_pred_all = merged['yhat'].values
        
        rmse_all = np.sqrt(mean_squared_error(y_true_all, y_pred_all))
        mae_all = mean_absolute_error(y_true_all, y_pred_all)
        mape_all = np.mean(np.abs((y_true_all - y_pred_all) / y_true_all)) * 100
        
        validation_metrics['overall'] = {
            'period': f"{months[0]} to {months[-1]}" if len(months) > 1 else str(months[0]),
            'days': len(merged),
            'rmse': float(rmse_all),
            'mae': float(mae_all),
            'mape': float(mape_all)
        }
        
        logger.info(f"  ğŸ“Š Overall: RMSE={rmse_all:.2f}, MAE={mae_all:.2f}, MAPE={mape_all:.2f}%")
        
        self.validation_metrics = validation_metrics
        
        with open(self.output_dir / 'validation_metrics.json', 'w', encoding='utf-8') as f:
            json.dump(validation_metrics, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… Validation completed")
        
        return validation_metrics
    
    # ========================================================================
    # 8. å¯è¦–åŒ–
    # ========================================================================
    def create_visualizations(self):
        """åŒ…æ‹¬çš„ãªå¯è¦–åŒ–ã‚’ä½œæˆ"""
        logger.info("ğŸ“Š Creating visualizations...")
        
        fig = plt.figure(figsize=(24, 16))
        gs = fig.add_gridspec(4, 3, hspace=0.4, wspace=0.3)
        
        # 1. æ™‚ç³»åˆ— + äºˆæ¸¬ + æ¤œè¨¼
        ax1 = fig.add_subplot(gs[0, :])
        ax1.plot(self.df_train['ds'], self.df_train['y'], 
                label='Training', linewidth=1, alpha=0.7, color='blue')
        
        if self.df_validation is not None:
            ax1.plot(self.df_validation['ds'], self.df_validation['y'], 
                    label='Validation (Actual)', linewidth=1.5, alpha=0.9, 
                    color='green', marker='o', markersize=3)
        
        if self.ensemble_forecast is not None:
            forecast = self.ensemble_forecast
            forecast_future = forecast[forecast['ds'] > self.df_train['ds'].max()]
            
            ax1.plot(forecast_future['ds'], forecast_future['yhat'], 
                    'r-', label='Forecast', linewidth=2)
            ax1.fill_between(forecast_future['ds'], 
                            forecast_future['yhat_lower'], 
                            forecast_future['yhat_upper'], 
                            alpha=0.2, color='red', label='95% CI')
        
        ax1.set_title('Time Series Forecast with Validation', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Date')
        ax1.set_ylabel('Call Volume')
        ax1.legend()
        ax1.grid(alpha=0.3)
        
        # 2. æ¤œè¨¼æœŸé–“æ‹¡å¤§
        ax2 = fig.add_subplot(gs[1, :])
        if self.df_validation is not None and self.ensemble_forecast is not None:
            val_start = self.df_validation['ds'].min() - timedelta(days=7)
            val_end = self.df_validation['ds'].max() + timedelta(days=7)
            
            df_plot = pd.concat([self.df_train, self.df_validation])
            df_plot = df_plot[(df_plot['ds'] >= val_start) & (df_plot['ds'] <= val_end)]
            
            forecast_plot = self.ensemble_forecast[
                (self.ensemble_forecast['ds'] >= val_start) & 
                (self.ensemble_forecast['ds'] <= val_end)
            ]
            
            ax2.plot(df_plot['ds'], df_plot['y'], 
                    label='Actual', linewidth=1.5, alpha=0.8, color='black', marker='o', markersize=4)
            ax2.plot(forecast_plot['ds'], forecast_plot['yhat'], 
                    'r-', label='Forecast', linewidth=2)
            ax2.fill_between(forecast_plot['ds'], 
                            forecast_plot['yhat_lower'], 
                            forecast_plot['yhat_upper'], 
                            alpha=0.2, color='red')
            
            ax2.axvspan(self.df_validation['ds'].min(), 
                       self.df_validation['ds'].max(), 
                       alpha=0.1, color='yellow', label='Validation Period')
            
            ax2.set_title('Validation Period Closeup', fontsize=14, fontweight='bold')
            ax2.set_xlabel('Date')
            ax2.set_ylabel('Call Volume')
            ax2.legend()
            ax2.grid(alpha=0.3)
        
        # 3. æœˆåˆ¥èª¤å·®
        ax3 = fig.add_subplot(gs[2, 0])
        if self.validation_metrics:
            metrics_list = []
            for key in ['month_1', 'month_2']:
                if key in self.validation_metrics:
                    metrics_list.append({
                        'Month': self.validation_metrics[key]['period'],
                        'MAE': self.validation_metrics[key]['mae'],
                        'RMSE': self.validation_metrics[key]['rmse'],
                        'MAPE': self.validation_metrics[key]['mape']
                    })
            
            if metrics_list:
                metrics_df = pd.DataFrame(metrics_list)
                x = np.arange(len(metrics_df))
                width = 0.25
                
                ax3.bar(x - width, metrics_df['MAE'], width, label='MAE', alpha=0.8)
                ax3.bar(x, metrics_df['RMSE'], width, label='RMSE', alpha=0.8)
                ax3.bar(x + width, metrics_df['MAPE']*10, width, label='MAPEÃ—10', alpha=0.8)
                
                ax3.set_xlabel('Month')
                ax3.set_ylabel('Error')
                ax3.set_title('Monthly Validation Metrics', fontsize=12, fontweight='bold')
                ax3.set_xticks(x)
                ax3.set_xticklabels(metrics_df['Month'])
                ax3.legend()
                ax3.grid(alpha=0.3)
        
        # 4. æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
        ax4 = fig.add_subplot(gs[2, 1])
        if self.df_validation is not None and self.ensemble_forecast is not None:
            forecast_val = self.ensemble_forecast[
                self.ensemble_forecast['ds'].isin(self.df_validation['ds'])
            ]
            merged = pd.merge(self.df_validation[['ds', 'y']], 
                            forecast_val[['ds', 'yhat']], on='ds')
            
            if len(merged) > 0:
                residuals = merged['y'] - merged['yhat']
                
                ax4.scatter(merged['yhat'], residuals, alpha=0.6, s=30)
                ax4.axhline(0, color='red', linestyle='--', linewidth=2)
                ax4.set_xlabel('Predicted')
                ax4.set_ylabel('Residual')
                ax4.set_title('Residual Plot', fontsize=12, fontweight='bold')
                ax4.grid(alpha=0.3)
        
        # 5. å®Ÿæ¸¬ vs äºˆæ¸¬
        ax5 = fig.add_subplot(gs[2, 2])
        if self.df_validation is not None and self.ensemble_forecast is not None:
            forecast_val = self.ensemble_forecast[
                self.ensemble_forecast['ds'].isin(self.df_validation['ds'])
            ]
            merged = pd.merge(self.df_validation[['ds', 'y']], 
                            forecast_val[['ds', 'yhat']], on='ds')
            
            if len(merged) > 0:
                ax5.scatter(merged['y'], merged['yhat'], alpha=0.6, s=30)
                
                min_val = min(merged['y'].min(), merged['yhat'].min())
                max_val = max(merged['y'].max(), merged['yhat'].max())
                ax5.plot([min_val, max_val], [min_val, max_val], 
                        'r--', linewidth=2, label='Perfect')
                
                ax5.set_xlabel('Actual')
                ax5.set_ylabel('Predicted')
                ax5.set_title('Actual vs Predicted', fontsize=12, fontweight='bold')
                ax5.legend()
                ax5.grid(alpha=0.3)
        
        # 6-8. è¨ºæ–­é–¢é€£
        y = self.df_train['y'].values
        
        ax6 = fig.add_subplot(gs[3, 0])
        ax6.hist(y, bins=50, alpha=0.7, edgecolor='black', density=True)
        ax6.set_title('Distribution', fontsize=12, fontweight='bold')
        ax6.set_xlabel('Call Volume')
        ax6.set_ylabel('Density')
        ax6.grid(alpha=0.3)
        
        ax7 = fig.add_subplot(gs[3, 1])
        stats.probplot(y, dist="norm", plot=ax7)
        ax7.set_title('Q-Q Plot', fontsize=12, fontweight='bold')
        ax7.grid(alpha=0.3)
        
        ax8 = fig.add_subplot(gs[3, 2])
        df_train_copy = self.df_train.copy()
        df_train_copy['weekday'] = df_train_copy['ds'].dt.dayofweek
        weekday_data = [df_train_copy[df_train_copy['weekday'] == i]['y'].values for i in range(7)]
        ax8.boxplot(weekday_data, labels=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])
        ax8.set_title('Box Plot by Weekday', fontsize=12, fontweight='bold')
        ax8.set_ylabel('Call Volume')
        ax8.grid(alpha=0.3)
        
        plt.savefig(self.output_dir / 'visualizations.png', dpi=150, bbox_inches='tight')
        plt.close()
        
        logger.info(f"âœ… Visualizations saved")
    
    # ========================================================================
    # 9. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    # ========================================================================
    def generate_report(self):
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        logger.info("ğŸ“ Generating report...")
        
        report = []
        report.append("=" * 80)
        report.append("Prophet Ultimate Predictor v3.0 - Maximum Accuracy Edition")
        report.append("=" * 80)
        report.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # 1. ãƒ‡ãƒ¼ã‚¿æƒ…å ±
        report.append("1. DATA INFORMATION")
        report.append("-" * 80)
        report.append(f"  Training: {self.df_train['ds'].min().date()} to {self.df_train['ds'].max().date()} ({len(self.df_train)} days)")
        report.append(f"  Validation: {self.df_validation['ds'].min().date()} to {self.df_validation['ds'].max().date()} ({len(self.df_validation)} days)")
        report.append(f"  Mean: {self.df_train['y'].mean():.1f}, Std: {self.df_train['y'].std():.1f}, CV: {self.df_train['y'].std() / self.df_train['y'].mean():.3f}")
        report.append("")
        
        # 2. è¨ºæ–­çµæœ
        report.append("2. DIAGNOSTICS")
        report.append("-" * 80)
        if self.diagnostics:
            if 'basic_stats' in self.diagnostics:
                stats_data = self.diagnostics['basic_stats']
                report.append(f"  CV: {stats_data['cv']:.3f}, Skewness: {stats_data['skewness']:.3f}")
            if 'weekday_effect' in self.diagnostics:
                week = self.diagnostics['weekday_effect']
                report.append(f"  Weekday effect: {'Significant' if week.get('has_effect') else 'Not significant'}")
            if 'outliers' in self.diagnostics:
                out = self.diagnostics['outliers']
                report.append(f"  Outliers: {out.get('count', 0)} ({out.get('percentage', 0):.2f}%)")
        report.append("")
        
        # 3. æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        if self.best_params:
            report.append("3. OPTUNA BEST PARAMETERS")
            report.append("-" * 80)
            for key, value in self.best_params.items():
                report.append(f"  {key}: {value}")
            report.append("")
        
        # 4. æ¤œè¨¼çµæœ
        if self.validation_metrics:
            report.append("4. VALIDATION RESULTS")
            report.append("-" * 80)
            
            if 'month_1' in self.validation_metrics:
                m1 = self.validation_metrics['month_1']
                report.append(f"  Month 1 ({m1['period']}): RMSE={m1['rmse']:.2f}, MAE={m1['mae']:.2f}, MAPE={m1['mape']:.2f}%")
            
            if 'month_2' in self.validation_metrics:
                m2 = self.validation_metrics['month_2']
                report.append(f"  Month 2 ({m2['period']}): RMSE={m2['rmse']:.2f}, MAE={m2['mae']:.2f}, MAPE={m2['mape']:.2f}%")
            
            if 'overall' in self.validation_metrics:
                overall = self.validation_metrics['overall']
                report.append(f"  Overall: RMSE={overall['rmse']:.2f}, MAE={overall['mae']:.2f}, MAPE={overall['mape']:.2f}%")
        
        report.append("")
        report.append("=" * 80)
        
        report_text = "\n".join(report)
        with open(self.output_dir / 'report.txt', 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        logger.info(f"âœ… Report saved")
        
        return report_text
    
    # ========================================================================
    # 10. ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    # ========================================================================
    def save_models(self, filepath: str = None):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        if filepath is None:
            filepath = self.output_dir / 'models.pkl'
        
        save_obj = {
            'models': self.models,
            'ensemble_forecast': self.ensemble_forecast,
            'best_params': self.best_params,
            'diagnostics': self.diagnostics,
            'validation_metrics': self.validation_metrics
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(save_obj, f)
        
        logger.info(f"âœ… Models saved to {filepath}")
    
    # ========================================================================
    # 11. å®Œå…¨å®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    # ========================================================================
    def fit_predict(self, filepath: str, validation_months: int = 2, 
                    optuna_trials: int = 200) -> Dict:
        """
        å®Œå…¨å®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ (æœ€å¤§ç²¾åº¦ç‰ˆ)
        
        Parameters
        ----------
        filepath : str
            CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        validation_months : int
            æ¤œè¨¼æœŸé–“ (æœˆæ•°ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2)
        optuna_trials : int
            Optunaè©¦è¡Œå›æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 200)
        
        Returns
        -------
        dict
            å…¨çµæœ
        """
        logger.info("ğŸš€ Starting Prophet Ultimate Predictor v3.0 (Maximum Accuracy Edition)...")
        
        # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self.load_data(filepath, validation_months=validation_months)
        
        # 2. è¨ºæ–­
        self.run_comprehensive_diagnostics()
        
        # 3. ç¥æ—¥ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        holidays = self.create_holiday_dataframe()
        
        # 4. Optunaæœ€é©åŒ–
        self.optimize_with_optuna(
            self.df_train, 
            holidays=holidays, 
            n_trials=optuna_trials,
            cv_horizon_days=30
        )
        
        # 5. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        self.fit_ensemble_models(self.df_train, holidays=holidays)
        
        # 6. æ¤œè¨¼
        self.validate_forecast()
        
        # 7. å¯è¦–åŒ–
        self.create_visualizations()
        
        # 8. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = self.generate_report()
        
        # 9. ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        self.save_models()
        
        # 10. äºˆæ¸¬çµæœã‚’CSVä¿å­˜
        if self.ensemble_forecast is not None:
            forecast_df = self.ensemble_forecast[
                self.ensemble_forecast['ds'] > self.df_train['ds'].max()
            ][['ds', 'yhat', 'yhat_lower', 'yhat_upper']].copy()
            forecast_df.to_csv(self.output_dir / 'forecast.csv', index=False)
            logger.info(f"âœ… Forecast saved")
        
        logger.info("=" * 80)
        logger.info("ğŸ‰ Pipeline completed!")
        logger.info(f"ğŸ“ Results: {self.output_dir}")
        logger.info("=" * 80)
        
        return {
            'diagnostics': self.diagnostics,
            'best_params': self.best_params,
            'models': self.models,
            'forecast': self.ensemble_forecast,
            'validation_metrics': self.validation_metrics,
            'report': report
        }


# ============================================================================
# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
# ============================================================================
if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Prophet Ultimate Predictor v3.0 - Maximum Accuracy Edition',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('filepath', type=str, help='Path to CSV file (ds, y columns)')
    parser.add_argument('--validation-months', type=int, default=2, 
                        help='Validation period in months (default: 2)')
    parser.add_argument('--optuna-trials', type=int, default=200, 
                        help='Optuna trials (default: 200)')
    parser.add_argument('--output', type=str, default='prophet_v3_results', 
                        help='Output directory')
    
    args = parser.parse_args()
    
    # å®Ÿè¡Œ
    predictor = ProphetUltimatePredictor(output_dir=args.output)
    results = predictor.fit_predict(
        args.filepath, 
        validation_months=args.validation_months,
        optuna_trials=args.optuna_trials
    )
    
    print("\n" + "=" * 80)
    print("ğŸ“Š FINAL RESULTS")
    print("=" * 80)
    print(results['report'])
