#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
==============================================================================
NeuralProphet Ultimate Predictor for Call Center v5.0
==============================================================================

ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼æ—¥æ¬¡å‘¼é‡äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  v5.0 (NeuralProphetç‰ˆ)
- ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®éç·šå½¢è‡ªå·±å›å¸° (AR-Net)
- è¶…é«˜ç²¾åº¦ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° (100+ features)
- Optunaãƒ™ã‚¤ã‚ºæœ€é©åŒ– (30+ hyperparameters)
- Quantile Lossæœ€é©åŒ–
- ã‚·ãƒ•ãƒˆè¨ˆç”»ç‰¹åŒ–è©•ä¾¡æŒ‡æ¨™ (wQL, WAPE, MASE)

ä¸»è¦æ©Ÿèƒ½:
---------
1. NeuralProphet AR-Net
   - è‡ªå‹•ãƒ©ã‚°é¸æŠ (1ã€œ365æ—¥)
   - éç·šå½¢ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
   - è¨“ç·´å¯èƒ½ãª seasonality
2. è¶…é«˜ç²¾åº¦ç‰¹å¾´é‡
   - Lagged regressors: çŸ­æœŸã€œé•·æœŸãƒ©ã‚° (12ç¨®é¡)
   - Future regressors: æ›œæ—¥ã€æœˆã€ç¥æ—¥ã€ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç‰¹å¾´ (50+)
   - Rolling features: rolling mean/std, EWM (20+)
   - Events: æ—¥æœ¬ã®ç¥æ—¥ã€ç‰¹æ®ŠæœŸé–“
3. è‡ªå‹•å¤‰æ›é¸æŠ
   - æ­£è¦æ€§æ¤œå®š (5ç¨®é¡)
   - Box-Cox, Yeo-Johnson, log, sqrt, reciprocal
4. Optunaæœ€é©åŒ–
   - 30+ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
   - Quantile loss (QL_60, QL_70)
   - æ™‚ç³»åˆ—CV
5. ã‚·ãƒ•ãƒˆè¨ˆç”»ç‰¹åŒ–è©•ä¾¡
   - wQL, WAPE, MASE
   - Peak day accuracy
   - Bias analysis
6. åŒ…æ‹¬çš„å¯è¦–åŒ–ã¨ãƒ¬ãƒãƒ¼ãƒˆ

ä½¿ç”¨ä¾‹:
-------
python neuralprophet_ultimate_predictor.py data.csv \\
    --validation-months 2 \\
    --optuna-trials 200 \\
    --n-lags 28 \\
    --ar-layers 64 \\
    --epochs 100 \\
    --quantile 0.6

ä½œæˆè€…: AI Assistant
ãƒãƒ¼ã‚¸ãƒ§ãƒ³: 5.0
æœ€çµ‚æ›´æ–°: 2026-02-19
ãƒ©ã‚¤ã‚»ãƒ³ã‚¹: MIT
"""

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import calendar
import json
import pickle
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
import sys
import argparse

# NeuralProphet
try:
    from neuralprophet import NeuralProphet, set_log_level
    set_log_level("ERROR")  # ãƒ­ã‚°æŠ‘åˆ¶
except ImportError:
    print("âŒ NeuralProphet not installed.")
    print("Run: pip install neuralprophet")
    print("Or: pip install neuralprophet[live]  # for live plotting")
    sys.exit(1)

# Optuna
try:
    import optuna
    optuna.logging.set_verbosity(optuna.logging.WARNING)
except ImportError:
    print("âŒ Optuna not installed. Run: pip install optuna")
    sys.exit(1)

# PyTorch (NeuralProphetã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰)
try:
    import torch
    if torch.cuda.is_available():
        print(f"âœ… GPUæ¤œå‡º: {torch.cuda.get_device_name(0)}")
        DEVICE = 'cuda'
    else:
        print("âœ… CPU ãƒ¢ãƒ¼ãƒ‰")
        DEVICE = 'cpu'
except ImportError:
    print("âš ï¸  PyTorch not installed. Run: pip install torch")
    DEVICE = 'cpu'

# çµ±è¨ˆãƒ»æ™‚ç³»åˆ—åˆ†æ
from scipy import stats
from scipy.stats import (normaltest, shapiro, jarque_bera, anderson, 
                         boxcox, yeojohnson, skew, kurtosis, zscore)
from scipy.special import inv_boxcox
from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer
from sklearn.metrics import mean_absolute_error, mean_squared_error
from statsmodels.tsa.stattools import adfuller, acf, pacf
from statsmodels.tsa.seasonal import STL
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# è©•ä¾¡æŒ‡æ¨™ã‚·ã‚¹ãƒ†ãƒ 
try:
    from evaluation_metrics_for_shift_planning import ShiftPlanningEvaluator
    SHIFT_EVAL_AVAILABLE = True
except ImportError:
    print("âš ï¸  evaluation_metrics_for_shift_planning not found.")
    print("Advanced shift planning metrics will not be available.")
    SHIFT_EVAL_AVAILABLE = False

# æ—¥æœ¬ã®ç¥æ—¥
try:
    import jpholiday
    JPHOLIDAY_AVAILABLE = True
except ImportError:
    print("âš ï¸  jpholiday not installed. Run: pip install jpholiday")
    JPHOLIDAY_AVAILABLE = False

# ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
try:
    from tqdm import tqdm
except ImportError:
    tqdm = lambda x, **kwargs: x


# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Hiragino Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("husl")


class NeuralProphetUltimatePredictor:
    """
    NeuralProphet v5.0 è¶…é«˜ç²¾åº¦äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
    
    Features:
    ---------
    - AR-Net (è‡ªå·±å›å¸°ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ)
    - 100+ ç‰¹å¾´é‡
    - Optunaæœ€é©åŒ– (30+ params)
    - Quantile lossæœ€é©åŒ–
    - ã‚·ãƒ•ãƒˆè¨ˆç”»ç‰¹åŒ–è©•ä¾¡
    """
    
    def __init__(self, output_dir: str = "output_neuralprophet"):
        """åˆæœŸåŒ–"""
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)
        
        # ãƒ‡ãƒ¼ã‚¿
        self.df_train = None
        self.df_train_original = None
        self.df_validation = None
        self.df_validation_original = None
        self.df_full = None
        self.df_full_original = None
        
        # ç‰¹å¾´é‡
        self.lagged_regressor_names = []
        self.future_regressor_names = []
        self.event_names = []
        
        # è¨ºæ–­çµæœ
        self.diagnostics = {}
        
        # ãƒ¢ãƒ‡ãƒ«ã¨äºˆæ¸¬
        self.best_params = {}
        self.model_validation = None
        self.model_production = None
        self.forecast_validation = None
        self.forecast_production = None
        self.validation_metrics = {}
        
        # å¤‰æ›æƒ…å ±
        self.transformation_info = {}
        
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.output_dir / "neuralprophet_v5.log"),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        self.logger.info("=" * 100)
        self.logger.info("NeuralProphet v5.0 è¶…é«˜ç²¾åº¦äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  åˆæœŸåŒ–å®Œäº†")
        self.logger.info(f"Device: {DEVICE}")
        self.logger.info("=" * 100)
    
    def load_data(self, filepath: str, date_col: str = "ds", 
                  target_col: str = "y") -> pd.DataFrame:
        """
        CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        
        Parameters
        ----------
        filepath : str
            CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        date_col : str
            æ—¥ä»˜ã‚«ãƒ©ãƒ å
        target_col : str
            ç›®çš„å¤‰æ•°ã‚«ãƒ©ãƒ å
        
        Returns
        -------
        pd.DataFrame
            èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿
        """
        self.logger.info(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹: {filepath}")
        
        df = pd.read_csv(filepath)
        
        # åˆ—åæ¨™æº–åŒ–
        if date_col not in df.columns and target_col not in df.columns:
            if len(df.columns) >= 2:
                df.columns = ['ds', 'y'] + list(df.columns[2:])
                self.logger.info(f"âœ“ åˆ—åã‚’è‡ªå‹•å¤‰æ›: {date_col} -> ds, {target_col} -> y")
        
        # æ—¥ä»˜å¤‰æ›
        df['ds'] = pd.to_datetime(df['ds'])
        df = df.sort_values('ds').reset_index(drop=True)
        
        # æ¬ æå€¤ãƒã‚§ãƒƒã‚¯
        missing = df[['ds', 'y']].isnull().sum()
        if missing.any():
            self.logger.warning(f"âš ï¸  æ¬ æå€¤æ¤œå‡º: {missing.to_dict()}")
            df = df.dropna(subset=['ds', 'y'])
        
        # é‡è¤‡æ—¥ä»˜ãƒã‚§ãƒƒã‚¯
        duplicates = df['ds'].duplicated().sum()
        if duplicates > 0:
            self.logger.warning(f"âš ï¸  é‡è¤‡æ—¥ä»˜æ¤œå‡º: {duplicates} ä»¶")
            df = df.drop_duplicates(subset=['ds'], keep='last')
        
        self.logger.info(f"âœ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)} è¡Œ")
        self.logger.info(f"  æœŸé–“: {df['ds'].min()} ã€œ {df['ds'].max()}")
        self.logger.info(f"  æ—¥æ•°: {(df['ds'].max() - df['ds'].min()).days + 1} æ—¥")
        self.logger.info(f"  ç›®çš„å¤‰æ•°çµ±è¨ˆ:")
        self.logger.info(f"    å¹³å‡: {df['y'].mean():.2f}")
        self.logger.info(f"    ä¸­å¤®å€¤: {df['y'].median():.2f}")
        self.logger.info(f"    æ¨™æº–åå·®: {df['y'].std():.2f}")
        self.logger.info(f"    æœ€å°å€¤: {df['y'].min():.2f}")
        self.logger.info(f"    æœ€å¤§å€¤: {df['y'].max():.2f}")
        self.logger.info(f"    å¤‰å‹•ä¿‚æ•°: {df['y'].std() / df['y'].mean():.4f}")
        
        return df
    
    def select_optimal_transformation(self, y: pd.Series) -> Dict:
        """
        ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ã«åŸºã¥ãæœ€é©ãªå¤‰æ›ã‚’è‡ªå‹•é¸æŠ
        
        Parameters
        ----------
        y : pd.Series
            å…ƒã®ç›®çš„å¤‰æ•°
        
        Returns
        -------
        Dict
            å¤‰æ›æƒ…å ± (method, transformed_y, lambda_param, metrics)
        """
        self.logger.info("=" * 100)
        self.logger.info("ğŸ”„ ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®è‡ªå‹•é¸æŠé–‹å§‹")
        self.logger.info("=" * 100)
        
        y_clean = y.dropna()
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆé‡
        original_stats = {
            'mean': y_clean.mean(),
            'std': y_clean.std(),
            'skewness': skew(y_clean),
            'kurtosis': kurtosis(y_clean),
            'min': y_clean.min(),
            'max': y_clean.max()
        }
        
        self.logger.info(f"ğŸ“Š å…ƒãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
        self.logger.info(f"  å¹³å‡: {original_stats['mean']:.2f}")
        self.logger.info(f"  æ¨™æº–åå·®: {original_stats['std']:.2f}")
        self.logger.info(f"  æ­ªåº¦: {original_stats['skewness']:.4f}")
        self.logger.info(f"  å°–åº¦: {original_stats['kurtosis']:.4f}")
        
        # æ­£è¦æ€§æ¤œå®š
        def test_normality(data):
            """æ­£è¦æ€§æ¤œå®š (5ç¨®é¡)"""
            tests = {}
            
            # 1. Shapiro-Wilk
            if len(data) < 5000:
                stat, p = shapiro(data)
                tests['shapiro'] = {'statistic': stat, 'pvalue': p}
            
            # 2. Kolmogorov-Smirnov
            stat, p = stats.kstest(data, 'norm', args=(data.mean(), data.std()))
            tests['ks'] = {'statistic': stat, 'pvalue': p}
            
            # 3. Anderson-Darling
            result = anderson(data, dist='norm')
            tests['anderson'] = {
                'statistic': result.statistic,
                'critical_values': result.critical_values.tolist(),
                'significance_levels': result.significance_level.tolist()
            }
            
            # 4. Jarque-Bera
            stat, p = jarque_bera(data)
            tests['jarque_bera'] = {'statistic': stat, 'pvalue': p}
            
            # 5. D'Agostino-Pearson
            stat, p = normaltest(data)
            tests['dagostino'] = {'statistic': stat, 'pvalue': p}
            
            return tests
        
        original_tests = test_normality(y_clean)
        
        self.logger.info("ğŸ”¬ å…ƒãƒ‡ãƒ¼ã‚¿ã®æ­£è¦æ€§æ¤œå®š:")
        for name, result in original_tests.items():
            if 'pvalue' in result:
                is_normal = "æ­£è¦" if result['pvalue'] > 0.05 else "éæ­£è¦"
                self.logger.info(f"  {name}: på€¤={result['pvalue']:.6f} ({is_normal})")
        
        # å¤‰æ›å€™è£œã‚’è©•ä¾¡
        transformations = []
        
        # 1. å¤‰æ›ãªã—
        transformations.append({
            'method': 'none',
            'y_transformed': y_clean,
            'lambda': None,
            'stats': original_stats,
            'tests': original_tests,
            'score': self._score_transformation(original_stats, original_tests)
        })
        
        # 2. å¯¾æ•°å¤‰æ› (y > 0)
        if y_clean.min() > 0:
            y_log = np.log(y_clean)
            log_stats = {
                'skewness': skew(y_log),
                'kurtosis': kurtosis(y_log)
            }
            log_tests = test_normality(y_log)
            transformations.append({
                'method': 'log',
                'y_transformed': y_log,
                'lambda': None,
                'stats': log_stats,
                'tests': log_tests,
                'score': self._score_transformation(log_stats, log_tests)
            })
        
        # 3. å¹³æ–¹æ ¹å¤‰æ› (y >= 0)
        if y_clean.min() >= 0:
            y_sqrt = np.sqrt(y_clean)
            sqrt_stats = {
                'skewness': skew(y_sqrt),
                'kurtosis': kurtosis(y_sqrt)
            }
            sqrt_tests = test_normality(y_sqrt)
            transformations.append({
                'method': 'sqrt',
                'y_transformed': y_sqrt,
                'lambda': None,
                'stats': sqrt_stats,
                'tests': sqrt_tests,
                'score': self._score_transformation(sqrt_stats, sqrt_tests)
            })
        
        # 4. Box-Coxå¤‰æ› (y > 0)
        if y_clean.min() > 0:
            try:
                y_boxcox, lambda_bc = boxcox(y_clean)
                bc_stats = {
                    'skewness': skew(y_boxcox),
                    'kurtosis': kurtosis(y_boxcox)
                }
                bc_tests = test_normality(y_boxcox)
                transformations.append({
                    'method': 'boxcox',
                    'y_transformed': pd.Series(y_boxcox, index=y_clean.index),
                    'lambda': lambda_bc,
                    'stats': bc_stats,
                    'tests': bc_tests,
                    'score': self._score_transformation(bc_stats, bc_tests)
                })
            except Exception as e:
                self.logger.warning(f"âš ï¸  Box-Coxå¤‰æ›å¤±æ•—: {e}")
        
        # 5. Yeo-Johnsonå¤‰æ› (å…¨ã¦ã®å€¤)
        try:
            y_yj, lambda_yj = yeojohnson(y_clean)
            yj_stats = {
                'skewness': skew(y_yj),
                'kurtosis': kurtosis(y_yj)
            }
            yj_tests = test_normality(y_yj)
            transformations.append({
                'method': 'yeojohnson',
                'y_transformed': pd.Series(y_yj, index=y_clean.index),
                'lambda': lambda_yj,
                'stats': yj_stats,
                'tests': yj_tests,
                'score': self._score_transformation(yj_stats, yj_tests)
            })
        except Exception as e:
            self.logger.warning(f"âš ï¸  Yeo-Johnsonå¤‰æ›å¤±æ•—: {e}")
        
        # 6. é€†æ•°å¤‰æ› (y != 0)
        if y_clean.min() > 0:
            y_reciprocal = 1 / y_clean
            recip_stats = {
                'skewness': skew(y_reciprocal),
                'kurtosis': kurtosis(y_reciprocal)
            }
            recip_tests = test_normality(y_reciprocal)
            transformations.append({
                'method': 'reciprocal',
                'y_transformed': y_reciprocal,
                'lambda': None,
                'stats': recip_stats,
                'tests': recip_tests,
                'score': self._score_transformation(recip_stats, recip_tests)
            })
        
        # æœ€é©ãªå¤‰æ›ã‚’é¸æŠ (ã‚¹ã‚³ã‚¢æœ€å¤§)
        best_transformation = max(transformations, key=lambda x: x['score'])
        
        self.logger.info("=" * 100)
        self.logger.info("ğŸ“‹ å¤‰æ›å€™è£œã®è©•ä¾¡çµæœ:")
        self.logger.info("=" * 100)
        for t in transformations:
            marker = "â­" if t == best_transformation else "  "
            self.logger.info(f"{marker} {t['method']:12s}: "
                           f"Score={t['score']:.4f}, "
                           f"Skewness={t['stats']['skewness']:7.4f}, "
                           f"Kurtosis={t['stats']['kurtosis']:7.4f}")
        
        self.logger.info("=" * 100)
        self.logger.info(f"âœ… é¸æŠã•ã‚ŒãŸå¤‰æ›: {best_transformation['method']}")
        if best_transformation['lambda'] is not None:
            self.logger.info(f"  Lambda: {best_transformation['lambda']:.4f}")
        self.logger.info("=" * 100)
        
        return best_transformation
    
    def _score_transformation(self, stats: Dict, tests: Dict) -> float:
        """
        å¤‰æ›ã®è‰¯ã•ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        
        Parameters
        ----------
        stats : Dict
            çµ±è¨ˆé‡ (skewness, kurtosis)
        tests : Dict
            æ­£è¦æ€§æ¤œå®šçµæœ
        
        Returns
        -------
        float
            ã‚¹ã‚³ã‚¢ (é«˜ã„ã»ã©è‰¯ã„)
        """
        score = 0.0
        
        # 1. æ­ªåº¦ãŒ0ã«è¿‘ã„ (+30ç‚¹æº€ç‚¹)
        score += 30 * np.exp(-abs(stats['skewness']))
        
        # 2. å°–åº¦ãŒ0ã«è¿‘ã„ (+30ç‚¹æº€ç‚¹)
        score += 30 * np.exp(-abs(stats['kurtosis']))
        
        # 3. æ­£è¦æ€§æ¤œå®š på€¤ > 0.05 (+40ç‚¹æº€ç‚¹)
        p_values = []
        for name, result in tests.items():
            if 'pvalue' in result:
                p_values.append(result['pvalue'])
        
        if p_values:
            avg_p = np.mean(p_values)
            score += 40 * (avg_p ** 0.5)  # å¹³æ–¹æ ¹ã§å¤‰æ› (p=1ã§æº€ç‚¹)
        
        return score
    
    def _apply_transformation(self, y: pd.Series, 
                             method: str, 
                             lambda_param: Optional[float] = None) -> pd.Series:
        """
        å¤‰æ›ã‚’é©ç”¨
        
        Parameters
        ----------
        y : pd.Series
            å…ƒãƒ‡ãƒ¼ã‚¿
        method : str
            å¤‰æ›æ–¹æ³•
        lambda_param : float, optional
            Box-Cox/Yeo-Johnsonã®Î»
        
        Returns
        -------
        pd.Series
            å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿
        """
        if method == 'none':
            return y
        elif method == 'log':
            return np.log(y)
        elif method == 'sqrt':
            return np.sqrt(y)
        elif method == 'boxcox':
            if lambda_param == 0:
                return pd.Series(np.log(y), index=y.index)
            else:
                return pd.Series((y ** lambda_param - 1) / lambda_param, index=y.index)
        elif method == 'yeojohnson':
            return pd.Series(yeojohnson(y, lmbda=lambda_param), index=y.index)
        elif method == 'reciprocal':
            return 1 / y
        else:
            raise ValueError(f"Unknown transformation: {method}")
    
    def _inverse_transformation(self, y_transformed: np.ndarray, 
                                method: str, 
                                lambda_param: Optional[float] = None) -> np.ndarray:
        """
        å¤‰æ›ã‚’é€†å¤‰æ›
        
        Parameters
        ----------
        y_transformed : np.ndarray
            å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿
        method : str
            å¤‰æ›æ–¹æ³•
        lambda_param : float, optional
            Box-Cox/Yeo-Johnsonã®Î»
        
        Returns
        -------
        np.ndarray
            å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã—ãŸãƒ‡ãƒ¼ã‚¿
        """
        if method == 'none':
            return y_transformed
        elif method == 'log':
            return np.exp(y_transformed)
        elif method == 'sqrt':
            return y_transformed ** 2
        elif method == 'boxcox':
            if lambda_param == 0:
                return np.exp(y_transformed)
            else:
                return (y_transformed * lambda_param + 1) ** (1 / lambda_param)
        elif method == 'yeojohnson':
            # Yeo-Johnsoné€†å¤‰æ›
            if lambda_param == 0:
                return np.exp(y_transformed) - 1
            elif lambda_param == 2:
                return np.exp(-y_transformed) - 1
            elif y_transformed >= 0:
                return (y_transformed * lambda_param + 1) ** (1 / lambda_param) - 1
            else:
                return 1 - ((-y_transformed) * (2 - lambda_param) + 1) ** (1 / (2 - lambda_param))
        elif method == 'reciprocal':
            return 1 / y_transformed
        else:
            raise ValueError(f"Unknown transformation: {method}")
    
    # ... (ç¶šã: ç‰¹å¾´é‡ç”Ÿæˆã€Optunaæœ€é©åŒ–ã€ãƒ¢ãƒ‡ãƒ«è¨“ç·´ãªã©)
    
    def generate_comprehensive_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è¶…åŒ…æ‹¬çš„ãªç‰¹å¾´é‡ç”Ÿæˆ (100+ features)
        
        NeuralProphetã«æœ€é©åŒ–:
        - Lagged regressors: éå»ã®å€¤ (AR-Netã§å­¦ç¿’)
        - Future regressors: å°†æ¥ã‚ã‹ã‚‹ç‰¹å¾´
        - Events: ç‰¹æ®Šæ—¥
        
        Parameters
        ----------
        df : pd.DataFrame
            å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ (ds, y)
        
        Returns
        -------
        pd.DataFrame
            ç‰¹å¾´é‡è¿½åŠ å¾Œã®ãƒ‡ãƒ¼ã‚¿
        """
        self.logger.info("=" * 100)
        self.logger.info("ğŸ”§ è¶…åŒ…æ‹¬çš„ç‰¹å¾´é‡ç”Ÿæˆé–‹å§‹ (100+ features)")
        self.logger.info("=" * 100)
        
        df = df.copy()
        df = df.sort_values('ds').reset_index(drop=True)
        
        # 1. ãƒ©ã‚°ç‰¹å¾´é‡ (Lagged Regressors)
        df = self._generate_lagged_features(df)
        
        # 2. ãƒ­ãƒ¼ãƒªãƒ³ã‚°çµ±è¨ˆ (Lagged Regressors)
        df = self._generate_rolling_features(df)
        
        # 3. æ™‚é–“ç‰¹å¾´ (Future Regressors)
        df = self._generate_time_features(df)
        
        # 4. ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç‰¹å¾´ (Future Regressors)
        df = self._generate_calendar_features(df)
        
        # 5. å¾ªç’°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° (Future Regressors)
        df = self._generate_cyclical_features(df)
        
        # 6. ã‚¤ãƒ™ãƒ³ãƒˆç‰¹å¾´ (Events)
        df = self._generate_event_features(df)
        
        # 7. ãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´ (Future Regressors)
        df = self._generate_trend_features(df)
        
        # æ¬ æå€¤å‡¦ç† (ãƒ©ã‚°ç‰¹å¾´ã«ã‚ˆã‚‹æ¬ æ)
        initial_rows = len(df)
        df = df.dropna()
        dropped_rows = initial_rows - len(df)
        
        if dropped_rows > 0:
            self.logger.info(f"âš ï¸  ãƒ©ã‚°ç‰¹å¾´ã«ã‚ˆã‚‹æ¬ æè¡Œå‰Šé™¤: {dropped_rows} è¡Œ")
        
        self.logger.info("=" * 100)
        self.logger.info(f"âœ… ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†")
        self.logger.info(f"  Lagged regressors: {len(self.lagged_regressor_names)} å€‹")
        self.logger.info(f"  Future regressors: {len(self.future_regressor_names)} å€‹")
        self.logger.info(f"  Events: {len(self.event_names)} å€‹")
        self.logger.info(f"  ç·ç‰¹å¾´é‡æ•°: {len(df.columns) - 2} å€‹ (ds, y ã‚’é™¤ã)")
        self.logger.info("=" * 100)
        
        return df
    
    def _generate_lagged_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ãƒ©ã‚°ç‰¹å¾´é‡ç”Ÿæˆ
        
        Lagged regressors: NeuralProphetã®AR-NetãŒå­¦ç¿’
        çŸ­æœŸã€œé•·æœŸã®ãƒ©ã‚°ã‚’ç¶²ç¾…
        """
        self.logger.info("ğŸ“Š ãƒ©ã‚°ç‰¹å¾´é‡ç”Ÿæˆä¸­...")
        
        # åŸºæœ¬ãƒ©ã‚° (1ã€œ7æ—¥: ç›´è¿‘1é€±é–“)
        for lag in [1, 2, 3, 4, 5, 6, 7]:
            col_name = f'lag_{lag}'
            df[col_name] = df['y'].shift(lag)
            self.lagged_regressor_names.append(col_name)
        
        # é€±æ¬¡ãƒ©ã‚° (7, 14, 21, 28æ—¥: éå»4é€±é–“ã®åŒæ›œæ—¥)
        for lag in [14, 21, 28]:
            col_name = f'lag_{lag}'
            df[col_name] = df['y'].shift(lag)
            self.lagged_regressor_names.append(col_name)
        
        # æœˆæ¬¡ãƒ©ã‚° (30, 60, 90æ—¥)
        for lag in [30, 60, 90]:
            col_name = f'lag_{lag}'
            df[col_name] = df['y'].shift(lag)
            self.lagged_regressor_names.append(col_name)
        
        # é•·æœŸãƒ©ã‚° (180, 365æ—¥: åŠå¹´ãƒ»1å¹´å‰)
        for lag in [180, 365]:
            if len(df) > lag:
                col_name = f'lag_{lag}'
                df[col_name] = df['y'].shift(lag)
                self.lagged_regressor_names.append(col_name)
        
        self.logger.info(f"  âœ“ ãƒ©ã‚°ç‰¹å¾´: {len(self.lagged_regressor_names)} å€‹")
        
        return df
    
    def _generate_rolling_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ãƒ­ãƒ¼ãƒªãƒ³ã‚°çµ±è¨ˆç‰¹å¾´
        
        Lagged regressors: rolling mean/std, EWM
        """
        self.logger.info("ğŸ“Š ãƒ­ãƒ¼ãƒªãƒ³ã‚°çµ±è¨ˆç‰¹å¾´ç”Ÿæˆä¸­...")
        
        # Rolling mean (7, 14, 28æ—¥)
        for window in [7, 14, 28]:
            col_name = f'rolling_mean_{window}'
            df[col_name] = df['y'].shift(1).rolling(window).mean()
            self.lagged_regressor_names.append(col_name)
        
        # Rolling std (7, 14, 28æ—¥)
        for window in [7, 14, 28]:
            col_name = f'rolling_std_{window}'
            df[col_name] = df['y'].shift(1).rolling(window).std()
            self.lagged_regressor_names.append(col_name)
        
        # Rolling min/max (7, 14æ—¥)
        for window in [7, 14]:
            col_name = f'rolling_min_{window}'
            df[col_name] = df['y'].shift(1).rolling(window).min()
            self.lagged_regressor_names.append(col_name)
            
            col_name = f'rolling_max_{window}'
            df[col_name] = df['y'].shift(1).rolling(window).max()
            self.lagged_regressor_names.append(col_name)
        
        # Exponential weighted mean (7, 14, 28æ—¥)
        for span in [7, 14, 28]:
            col_name = f'ewm_{span}'
            df[col_name] = df['y'].shift(1).ewm(span=span).mean()
            self.lagged_regressor_names.append(col_name)
        
        # å¤‰å‹•ä¿‚æ•° (CV: coefficient of variation)
        for window in [7, 14, 28]:
            mean_col = f'rolling_mean_{window}'
            std_col = f'rolling_std_{window}'
            if mean_col in df.columns and std_col in df.columns:
                col_name = f'cv_{window}'
                df[col_name] = df[std_col] / (df[mean_col] + 1e-10)
                self.lagged_regressor_names.append(col_name)
        
        self.logger.info(f"  âœ“ ãƒ­ãƒ¼ãƒªãƒ³ã‚°ç‰¹å¾´: {len([n for n in self.lagged_regressor_names if 'rolling' in n or 'ewm' in n or 'cv' in n])} å€‹")
        
        return df
    
    def _generate_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ™‚é–“ç‰¹å¾´ (Future Regressors)
        
        æ›œæ—¥ã€æœˆã€å››åŠæœŸãªã©
        """
        self.logger.info("ğŸ“… æ™‚é–“ç‰¹å¾´ç”Ÿæˆä¸­...")
        
        # æ›œæ—¥ (0=æœˆæ›œ, 6=æ—¥æ›œ)
        df['dayofweek'] = df['ds'].dt.dayofweek
        self.future_regressor_names.append('dayofweek')
        
        # æ›œæ—¥ãƒ€ãƒŸãƒ¼ (one-hot)
        for dow in range(7):
            col_name = f'dow_{dow}'
            df[col_name] = (df['dayofweek'] == dow).astype(int)
            self.future_regressor_names.append(col_name)
        
        # æœˆ (1-12)
        df['month'] = df['ds'].dt.month
        self.future_regressor_names.append('month')
        
        # æœˆãƒ€ãƒŸãƒ¼ (one-hot)
        for month in range(1, 13):
            col_name = f'month_{month}'
            df[col_name] = (df['month'] == month).astype(int)
            self.future_regressor_names.append(col_name)
        
        # å››åŠæœŸ (1-4)
        df['quarter'] = df['ds'].dt.quarter
        self.future_regressor_names.append('quarter')
        
        # å››åŠæœŸãƒ€ãƒŸãƒ¼
        for q in range(1, 5):
            col_name = f'quarter_{q}'
            df[col_name] = (df['quarter'] == q).astype(int)
            self.future_regressor_names.append(col_name)
        
        # å¹´
        df['year'] = df['ds'].dt.year
        self.future_regressor_names.append('year')
        
        # æœˆå†…æ—¥ (1-31)
        df['day_of_month'] = df['ds'].dt.day
        self.future_regressor_names.append('day_of_month')
        
        # å¹´å†…æ—¥ (1-365/366)
        df['day_of_year'] = df['ds'].dt.dayofyear
        self.future_regressor_names.append('day_of_year')
        
        # å¹´å†…é€± (1-53)
        df['week_of_year'] = df['ds'].dt.isocalendar().week.astype(int)
        self.future_regressor_names.append('week_of_year')
        
        # æœˆå†…é€± (1-5)
        df['week_of_month'] = ((df['day_of_month'] - 1) // 7 + 1)
        self.future_regressor_names.append('week_of_month')
        
        self.logger.info(f"  âœ“ æ™‚é–“ç‰¹å¾´: {len([n for n in self.future_regressor_names if 'dow' in n or 'month' in n or 'quarter' in n or 'year' in n or 'day' in n or 'week' in n])} å€‹")
        
        return df
    
    def _generate_calendar_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç‰¹å¾´ (Future Regressors)
        
        å¹³æ—¥/é€±æœ«ã€æœˆåˆæœˆæœ«ãªã©
        """
        self.logger.info("ğŸ“† ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç‰¹å¾´ç”Ÿæˆä¸­...")
        
        # å¹³æ—¥/é€±æœ«
        df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)
        self.future_regressor_names.append('is_weekend')
        
        # æœˆæ›œãƒ»é‡‘æ›œãƒ•ãƒ©ã‚°
        df['is_monday'] = (df['dayofweek'] == 0).astype(int)
        df['is_friday'] = (df['dayofweek'] == 4).astype(int)
        self.future_regressor_names.extend(['is_monday', 'is_friday'])
        
        # æœˆåˆ (1-5æ—¥)
        df['is_month_start'] = (df['day_of_month'] <= 5).astype(int)
        self.future_regressor_names.append('is_month_start')
        
        # æœˆæœ« (26-31æ—¥)
        df['days_in_month'] = df['ds'].dt.days_in_month
        df['is_month_end'] = (df['day_of_month'] >= df['days_in_month'] - 5).astype(int)
        self.future_regressor_names.append('is_month_end')
        
        # æœˆä¸­æ—¬ (10-20æ—¥)
        df['is_mid_month'] = ((df['day_of_month'] >= 10) & (df['day_of_month'] <= 20)).astype(int)
        self.future_regressor_names.append('is_mid_month')
        
        # æœˆæœ«ã¾ã§ã®æ—¥æ•°
        df['days_to_month_end'] = df['days_in_month'] - df['day_of_month']
        self.future_regressor_names.append('days_to_month_end')
        
        # å››åŠæœŸåˆãƒ»å››åŠæœŸæœ«
        df['is_quarter_start'] = df['ds'].dt.is_quarter_start.astype(int)
        df['is_quarter_end'] = df['ds'].dt.is_quarter_end.astype(int)
        self.future_regressor_names.extend(['is_quarter_start', 'is_quarter_end'])
        
        # å¹´åˆãƒ»å¹´æœ«
        df['is_year_start'] = (df['day_of_year'] <= 5).astype(int)
        df['is_year_end'] = (df['day_of_year'] >= 360).astype(int)
        self.future_regressor_names.extend(['is_year_start', 'is_year_end'])
        
        self.logger.info(f"  âœ“ ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç‰¹å¾´: {len([n for n in self.future_regressor_names if 'is_' in n or 'days_' in n])} å€‹")
        
        return df
    
    def _generate_cyclical_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å¾ªç’°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° (Future Regressors)
        
        sin/coså¤‰æ›ã§å‘¨æœŸæ€§ã‚’è¡¨ç¾
        """
        self.logger.info("ğŸ”„ å¾ªç’°ç‰¹å¾´ç”Ÿæˆä¸­...")
        
        # æ›œæ—¥ (å‘¨æœŸ=7)
        df['dow_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)
        df['dow_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)
        self.future_regressor_names.extend(['dow_sin', 'dow_cos'])
        
        # æœˆ (å‘¨æœŸ=12)
        df['month_sin'] = np.sin(2 * np.pi * (df['month'] - 1) / 12)
        df['month_cos'] = np.cos(2 * np.pi * (df['month'] - 1) / 12)
        self.future_regressor_names.extend(['month_sin', 'month_cos'])
        
        # æœˆå†…æ—¥ (å‘¨æœŸ=31)
        df['day_sin'] = np.sin(2 * np.pi * (df['day_of_month'] - 1) / 31)
        df['day_cos'] = np.cos(2 * np.pi * (df['day_of_month'] - 1) / 31)
        self.future_regressor_names.extend(['day_sin', 'day_cos'])
        
        # å¹´å†…æ—¥ (å‘¨æœŸ=365)
        df['doy_sin'] = np.sin(2 * np.pi * (df['day_of_year'] - 1) / 365)
        df['doy_cos'] = np.cos(2 * np.pi * (df['day_of_year'] - 1) / 365)
        self.future_regressor_names.extend(['doy_sin', 'doy_cos'])
        
        # å››åŠæœŸ (å‘¨æœŸ=4)
        df['quarter_sin'] = np.sin(2 * np.pi * (df['quarter'] - 1) / 4)
        df['quarter_cos'] = np.cos(2 * np.pi * (df['quarter'] - 1) / 4)
        self.future_regressor_names.extend(['quarter_sin', 'quarter_cos'])
        
        self.logger.info(f"  âœ“ å¾ªç’°ç‰¹å¾´: {len([n for n in self.future_regressor_names if 'sin' in n or 'cos' in n])} å€‹")
        
        return df
    
    def _generate_event_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ã‚¤ãƒ™ãƒ³ãƒˆç‰¹å¾´ (Events)
        
        æ—¥æœ¬ã®ç¥æ—¥ã€ç‰¹æ®ŠæœŸé–“
        """
        self.logger.info("ğŸŒ ã‚¤ãƒ™ãƒ³ãƒˆç‰¹å¾´ç”Ÿæˆä¸­...")
        
        if not JPHOLIDAY_AVAILABLE:
            self.logger.warning("  âš ï¸  jpholidayæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« â†’ ã‚¤ãƒ™ãƒ³ãƒˆç‰¹å¾´ã‚¹ã‚­ãƒƒãƒ—")
            return df
        
        # ç¥æ—¥ãƒ•ãƒ©ã‚°
        df['is_holiday'] = df['ds'].apply(lambda x: jpholiday.is_holiday(x)).astype(int)
        self.event_names.append('is_holiday')
        
        # ç¥æ—¥åå–å¾—
        df['holiday_name'] = df['ds'].apply(
            lambda x: jpholiday.is_holiday_name(x) if jpholiday.is_holiday(x) else None
        )
        
        # ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¦ã‚£ãƒ¼ã‚¯ (4/29 - 5/5)
        df['is_golden_week'] = (
            (df['month'] == 4) & (df['day_of_month'] >= 29) |
            (df['month'] == 5) & (df['day_of_month'] <= 5)
        ).astype(int)
        self.event_names.append('is_golden_week')
        
        # ãŠç›† (8/13 - 8/16)
        df['is_obon'] = (
            (df['month'] == 8) & 
            (df['day_of_month'] >= 13) & 
            (df['day_of_month'] <= 16)
        ).astype(int)
        self.event_names.append('is_obon')
        
        # å¹´æœ«å¹´å§‹ (12/29 - 1/3)
        df['is_year_end_new_year'] = (
            (df['month'] == 12) & (df['day_of_month'] >= 29) |
            (df['month'] == 1) & (df['day_of_month'] <= 3)
        ).astype(int)
        self.event_names.append('is_year_end_new_year')
        
        # ã‚·ãƒ«ãƒãƒ¼ã‚¦ã‚£ãƒ¼ã‚¯ (9æœˆã®é€£ä¼‘)
        df['is_silver_week'] = (
            (df['month'] == 9) & 
            (df['day_of_month'] >= 15) & 
            (df['day_of_month'] <= 23) &
            (df['is_holiday'] == 1)
        ).astype(int)
        self.event_names.append('is_silver_week')
        
        # ç¥æ—¥å‰æ—¥ãƒ»ç¿Œæ—¥
        df['is_holiday_before'] = df['is_holiday'].shift(-1).fillna(0).astype(int)
        df['is_holiday_after'] = df['is_holiday'].shift(1).fillna(0).astype(int)
        self.event_names.extend(['is_holiday_before', 'is_holiday_after'])
        
        self.logger.info(f"  âœ“ ã‚¤ãƒ™ãƒ³ãƒˆç‰¹å¾´: {len(self.event_names)} å€‹")
        
        return df
    
    def _generate_trend_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´ (Future Regressors)
        
        æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€æˆé•·ç‡ãªã©
        """
        self.logger.info("ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´ç”Ÿæˆä¸­...")
        
        # æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (0, 1, 2, ...)
        df['t'] = np.arange(len(df))
        self.future_regressor_names.append('t')
        
        # æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®2ä¹—ã€3ä¹—
        df['t_squared'] = df['t'] ** 2
        df['t_cubed'] = df['t'] ** 3
        self.future_regressor_names.extend(['t_squared', 't_cubed'])
        
        # æ­£è¦åŒ–æ™‚é–“ (0-1)
        df['t_normalized'] = df['t'] / (len(df) - 1)
        self.future_regressor_names.append('t_normalized')
        
        self.logger.info(f"  âœ“ ãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´: {len([n for n in self.future_regressor_names if 't' in n and 'month' not in n])} å€‹")
        
        return df

